{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a22262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classlabels(x):\n",
    "    if(x=='sachin'):\n",
    "        return 0\n",
    "    elif(x=='obama'):\n",
    "        return 1\n",
    "    elif(x=='messi'):\n",
    "        return 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "206e6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_class_names(x):\n",
    "    if(x==0):\n",
    "        return 'sachin'\n",
    "    elif(x==1):\n",
    "        return 'obama'\n",
    "    elif(x==2):\n",
    "        return 'messi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4094308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4027cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(img):\n",
    "    img_gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    c=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    face=c.detectMultiScale(img_gray,minNeighbors=4)\n",
    "    if(len(face)==0):\n",
    "        return None,None #incase face in that particular img is detected.\n",
    "    else:\n",
    "        x,y,w,h=face[0]\n",
    "        return img_gray[y:y+h,x:x+w],face[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e86516d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfeb794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_model(datafolder):\n",
    "    lis=os.listdir(datafolder)\n",
    "    faces=[]\n",
    "    labels=[]\n",
    "    for i in lis:\n",
    "        subpath=os.path.join(datafolder,i)\n",
    "        liss=os.listdir(subpath)\n",
    "        for j in liss:\n",
    "            imgpath=os.path.join(subpath,j)\n",
    "            img=cv2.imread(imgpath)\n",
    "            face_img,face_cord=face_detection(img)\n",
    "            if (face_img is not None):\n",
    "                faces.append(face_img)\n",
    "                labels.append(classlabels(i))\n",
    "                print(labels)\n",
    "\n",
    "    return faces,labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a6ba992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[2, 2]\n",
      "[2, 2, 2]\n",
      "[2, 2, 2, 2]\n",
      "[2, 2, 2, 2, 2]\n",
      "[2, 2, 2, 2, 2, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "faces,labels=prepare_training_model(r'C:\\Users\\fidha\\OneDrive\\Desktop\\LUMINAR\\DATASETS\\Face Recognition\\DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92716e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)\n",
    "# o/t is 29...out of 30 images ..in one image face wasnt detected and hence didnt get added to faces and labels..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d0e2279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.face.LBPHFaceRecognizer 0000025D9D50F870>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=cv2.face.LBPHFaceRecognizer_create()# Local Binary patterns Histogram\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c1c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e04dd551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# faces=np.array(faces) cannot convert to an array due to its varying shapes of images...but it can be passed\n",
    "# as a list to lbph model\n",
    "\n",
    "labels=np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "617af182",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.train(faces,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1da06bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectangle(img,face_cord):\n",
    "    x,y,w,h=face_cord\n",
    "    cv2.rectangle(img,pt1=(x,y),pt2=(x+w,y+h),thickness=2,color=[23,123,255])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09aa921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text(img,text,x,y):\n",
    "    cv2.putText(img,text,org=(x,y),thickness=2,fontFace=cv2.FONT_HERSHEY_SIMPLEX,fontScale=1,color=[120,244,56])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08b5d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_new(newimg):\n",
    "    f,face_cord=face_detection(newimg)\n",
    "    o=r.predict(f)\n",
    "    rectangle(newimg,face_cord)\n",
    "    text(newimg,return_class_names(o[0]),face_cord[0],face_cord[1])\n",
    "    cv2.imshow(\"window\",newimg)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "newimg=cv2.imread('messi1.jpeg')\n",
    "predict_new(newimg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
